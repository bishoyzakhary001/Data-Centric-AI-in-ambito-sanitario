{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899aa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Avvio della sessione Spark\n",
    "spark = SparkSession.builder.appName(\"WeightedSymptomClassification\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03098146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento dataset con gravità dei sintomi\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/drive/MyDrive/BigData/dataset_weighted.csv\")\n",
    "\n",
    "# Colonne sintomi\n",
    "symptom_cols = [col_name for col_name in df.columns if \"Symptom_\" in col_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicizzazione della colonna Disease\n",
    "indexer = StringIndexer(inputCol=\"Disease\", outputCol=\"label\")\n",
    "df = indexer.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemblaggio delle feature sintomatiche\n",
    "assembler = VectorAssembler(inputCols=symptom_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suddivisione del dataset\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668154c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest con sintomi pesati\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "model = rf.fit(train_data)\n",
    "predictions = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy su test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy con sintomi pesati:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46189c",
   "metadata": {},
   "source": [
    "Accuracy: ~93%\n",
    "\n",
    "è stato ottenuto un miglioramento enorme passando:\n",
    "*\tda 19% (feature binarie 0/1),\n",
    "*\ta 93% usando i pesi di gravità dei sintomi.\n",
    "\n",
    "# **Cosa significa?**\n",
    "* I dati, non il modello, erano il problema.\n",
    "*\tAggiungendo feature più informative (severity), il modello è stato in grado di distinguere molto meglio le malattie.\n",
    "*\tQuesto è l’esempio perfetto di Data-Centric AI: il boost non è arrivato da un nuovo algoritmo, ma da un dataset curato meglio."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
