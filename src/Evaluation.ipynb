{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Avvio Spark\n",
    "spark = SparkSession.builder.appName(\"Evaluation\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abe6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset con sintomi pesati\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/content/drive/MyDrive/BigData/dataset_weighted.csv\")\n",
    "symptom_cols = [col_name for col_name in df.columns if \"Symptom_\" in col_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"Disease\", outputCol=\"label\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=symptom_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbcfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "model = rf.fit(train_data)\n",
    "predictions = model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a118ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_prec = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_rec = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "print(\"Accuracy:\", evaluator_acc.evaluate(predictions))\n",
    "print(\"F1-score:\", evaluator_f1.evaluate(predictions))\n",
    "print(\"Precision:\", evaluator_prec.evaluate(predictions))\n",
    "print(\"Recall:\", evaluator_rec.evaluate(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversione in Pandas\n",
    "pdf = predictions.select(\"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(pdf[\"label\"], pdf[\"prediction\"])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report completo\n",
    "print(classification_report(pdf[\"label\"], pdf[\"prediction\"]))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
