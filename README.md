#Data-Centric AI in Healthcare

Big Data course project addressing the distributed classification of diseases from symptom descriptions.
This project follows a Data-Centric AI approach, focusing on profiling, cleaning, and automatic enrichment of symptom data to improve the quality and accuracy of the model.


#We used:
	â€¢Apache Spark (PySpark MLlib) for preprocessing and distributed classification
	â€¢MLflow for experiment tracking
	â€¢Flask for the web interface
	â€¢Random Forest and Gradient Boosted Trees for classification

##ðŸ“¦ Installing the requirements

##To install all dependencies:
```bash
pip3 install -r requirements.txt
```

##How it works

The symptoms_db.json file stores all information about symptoms and diseases, predicted values, and the confusion matrix.
If you want to add new symptoms, simply extend the JSON structure following the mapping defined in symptom_mapping.json.

##Example:
```json
{
    {
  "symptoms": ["fever", "cough", "fatigue"],
  "disease": "flu"
}
}
```
##Run server

To launch the web interface:
```bash
export FLASK_APP=app   # only the first time
flask run
```
##ðŸ”„ Pipeline
	1.	Data Preprocessing
	  	â€¢Remove records with insufficient symptoms
	  	â€¢Standardize and automatically translate symptoms
	  	â€¢Balance underrepresented classes
	2.Distributed Training with Spark
	  	â€¢Extract symptom-based features
	  	â€¢Train Random Forest and GBT on Spark MLlib
	  	â€¢Track experiments with MLflow
	3.Model Deployment
  	â€¢Save the model as .pkl
  	â€¢Integrate with Flask API

##Results
  	â€¢Initial accuracy: 19% â†’ after cleaning & enrichment â†’ 93%
  	â€¢Confusion matrix stored in results/confusion_matrix.png
  	â€¢MLflow UI available for monitoring model runs

   
